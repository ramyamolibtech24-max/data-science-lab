{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtKmHOXQFrSb"
   },
   "source": [
    "<h2 style=\"color:green\" align=\"center\">Predicting if a person would buy life insurnace based on his age using logistic regression</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLXyKCM-FrSd"
   },
   "source": [
    "Above is a binary logistic regression problem as there are only two possible outcomes (i.e. if person buys insurance or he/she doesn't)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qKfSr2toFrSe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Uz7nNXa0FrSf",
    "outputId": "243774c0-8ad2-4cd2-bb4b-7b701bc07e61"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"insurance_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "s2HAmRN1FrSg",
    "outputId": "b6c286a5-f840-4c0c-b209-18fff6b7fd01"
   },
   "outputs": [],
   "source": [
    "plt.scatter(df.age,df.bought_insurance,marker='+',color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M94L5mN0FrSh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNMs__3DFrSh"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['age']],df.bought_insurance,train_size=0.8,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "hhUyd4NoFrSh",
    "outputId": "7f64b35a-6dc7-4ecf-932d-3a83a740d4c8"
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVaaS1pEFrSi"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "wBYdAieGFrSj",
    "outputId": "5c32638d-53cd-4fd3-f2d9-75ed7648bcd6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "pdjcuH_3FrSj",
    "outputId": "780dd8c8-080b-49a0-e013-4670b1943b26"
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gD-ImepRFrSk"
   },
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdPJnkkfFrSl",
    "outputId": "62f40eaa-6640-4430-b63d-8be5a2737374"
   },
   "outputs": [],
   "source": [
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abjV2J6aFrSl",
    "outputId": "ab7a7257-30fd-4211-e589-65ef16ed6ff5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lh_qytcLFrSm",
    "outputId": "48f3f770-6944-4d8d-fb70-f8b190b9dcaf"
   },
   "outputs": [],
   "source": [
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "_-Owp3LoFrSm",
    "outputId": "7867a96a-7a18-43f5-b605-4de6bd4958a6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QHqnCWoFrSn"
   },
   "source": [
    "**model.coef_ indicates value of m in y=m*x + b equation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guBz36_LFrSn",
    "outputId": "e1761280-6bd9-4c6d-94cb-4b065429ba7f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2D8PhFOGFrSn"
   },
   "source": [
    "**model.intercept_ indicates value of b in y=m*x + b equation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25epLvD5FrSn",
    "outputId": "1c9779fe-16ab-4a04-9944-aba469c29c62",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KdlgVFNFrSo"
   },
   "source": [
    "**Lets defined sigmoid function now and do the math with hand**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2iYdtwLJFrSo"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GckQAwPKFrSo"
   },
   "outputs": [],
   "source": [
    "def prediction_function(age):\n",
    "    z = 0.161 * age - 5.80\n",
    "    y = sigmoid(z)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yKV4RUZsQbI"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ysYlC5wFrSo",
    "outputId": "bb747bd7-43b5-4185-9388-7c85c9625c9f"
   },
   "outputs": [],
   "source": [
    "age = 30\n",
    "prediction_function(age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Src_t1tUFrSp"
   },
   "source": [
    "**0.274 is less than 0.5 which means person with 35 age will *not* buy insurance**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BPlsQir_FrSp",
    "outputId": "632e38e6-63b5-4be7-b2d4-90e538e2fa42",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age = 43\n",
    "prediction_function(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUfIXXPFFyb_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# ---------------------------\n",
    "# Step 1: Load dataset\n",
    "# ---------------------------\n",
    "df = pd.read_csv(\"/content/weight-height.csv\")\n",
    "\n",
    "# Encode Gender: Male = 1, Female = 0\n",
    "df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "X = df[['Height', 'Weight']].values\n",
    "y = df['Gender'].values.reshape(-1, 1)\n",
    "\n",
    "# Normalize features\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "# Add bias term (intercept)\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])  # shape (n, 3)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 2: Sigmoid Function\n",
    "# ---------------------------\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# ---------------------------\n",
    "# Step 3: Loss Function (Binary Cross Entropy)\n",
    "# ---------------------------\n",
    "def compute_loss(y, y_pred):\n",
    "    m = len(y)\n",
    "    epsilon = 1e-8  # avoid log(0)\n",
    "    return - (1/m) * np.sum(y * np.log(y_pred + epsilon) + (1-y) * np.log(1 - y_pred + epsilon))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-xYoF62ascwB"
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Step 4: Gradient Descent\n",
    "# ---------------------------\n",
    "def gradient_descent(X, y, lr=0.01, epochs=1000):\n",
    "\n",
    "\n",
    "    return theta, loss_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPEIp0rksx8R"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Step 5: Train Model\n",
    "# ---------------------------\n",
    "theta, loss_history = gradient_descent(X, y, lr=0.1, epochs=1000)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 6: Predictions\n",
    "# ---------------------------\n",
    "y_pred_prob = sigmoid(np.dot(X, theta))\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "# ---------------------------\n",
    "# Step 7: Plot Loss Curve\n",
    "# ---------------------------\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------\n",
    "# Step 8: Confusion Matrix\n",
    "# ---------------------------\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Female\", \"Male\"],\n",
    "            yticklabels=[\"Female\", \"Male\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------\n",
    "# Step 9: Classification Report\n",
    "# ---------------------------\n",
    "print(classification_report(y, y_pred, target_names=[\"Female\", \"Male\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jAK2RFdaFrSp"
   },
   "source": [
    "<h2 style=\"color:purple\">Exercise</h2>\n",
    "\n",
    "Download employee retention dataset from here: https://www.kaggle.com/giripujar/hr-analytics.\n",
    "1. Now do some exploratory data analysis to figure out which variables have direct and clear impact on employee retention (i.e. whether they leave the company or continue to work)\n",
    "2. Plot bar charts showing impact of employee salaries on retention\n",
    "3. Plot bar charts showing corelation between department and employee retention\n",
    "4. Now build logistic regression model using variables that were narrowed down in step 1\n",
    "5. Measure the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# LOGISTIC REGRESSION EXERCISE - HR ANALYTICS DATASET\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# STEP 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 2: Load Data (with delimiter check)\n",
    "# ------------------------------------------------------------\n",
    "filename = \"HR_comma_sep.xls.csv\"\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    try:\n",
    "        # Try reading normally\n",
    "        data = pd.read_csv(filename)\n",
    "    except:\n",
    "        # Try alternate separator\n",
    "        data = pd.read_csv(filename, sep=';')\n",
    "    print(f\"✅ File found and loaded successfully: {filename}\")\n",
    "else:\n",
    "    print(\"⚠️ File not found in current directory.\")\n",
    "    print(\"Please select the file manually...\")\n",
    "    Tk().withdraw()\n",
    "    file_path = askopenfilename(title=\"Select HR_comma_sep.xls.csv file\")\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "    except:\n",
    "        data = pd.read_csv(file_path, sep=';')\n",
    "    print(f\"✅ File loaded successfully from: {file_path}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 3: Clean and Inspect Data\n",
    "# ------------------------------------------------------------\n",
    "# Sometimes the dataset gets loaded with one string column - fix that\n",
    "if data.shape[1] == 1:\n",
    "    data = data[data.columns[0]].str.split(',', expand=True)\n",
    "\n",
    "# Assign column names if missing\n",
    "expected_cols = ['satisfaction_level', 'last_evaluation', 'number_project', \n",
    "                 'average_montly_hours', 'time_spend_company', 'Work_accident', \n",
    "                 'left', 'promotion_last_5years', 'sales', 'salary']\n",
    "if len(data.columns) == 10:\n",
    "    data.columns = expected_cols\n",
    "\n",
    "# Convert numeric columns to float\n",
    "for col in ['satisfaction_level', 'last_evaluation', 'number_project', \n",
    "            'average_montly_hours', 'time_spend_company', 'Work_accident', \n",
    "            'left', 'promotion_last_5years']:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "\n",
    "print(\"\\n✅ Dataset cleaned successfully!\")\n",
    "display(data.head())\n",
    "print(\"\\nInfo:\")\n",
    "print(data.info())\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 4: Exploratory Data Analysis (EDA)\n",
    "# ------------------------------------------------------------\n",
    "corr = data.corr(numeric_only=True)['left'].sort_values(ascending=False)\n",
    "print(\"\\nCorrelation of features with employee leaving:\")\n",
    "print(corr)\n",
    "\n",
    "# 4.1 Visualizations\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x='left', y='satisfaction_level', data=data, palette='coolwarm')\n",
    "plt.title('Satisfaction Level vs Employee Leaving')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x='left', y='average_montly_hours', data=data, palette='coolwarm')\n",
    "plt.title('Average Monthly Hours vs Employee Leaving')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x='left', y='number_project', data=data, palette='coolwarm')\n",
    "plt.title('Number of Projects vs Employee Leaving')\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 5: Bar charts - Salary and Department impact\n",
    "# ------------------------------------------------------------\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.countplot(x='salary', hue='left', data=data, palette='Set2')\n",
    "plt.title(\"Impact of Salary on Employee Retention\")\n",
    "plt.xlabel(\"Salary Level\")\n",
    "plt.ylabel(\"Number of Employees\")\n",
    "plt.legend([\"Stayed\", \"Left\"])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(x='sales', hue='left', data=data, palette='Set3')\n",
    "plt.title(\"Impact of Department on Employee Retention\")\n",
    "plt.xlabel(\"Department\")\n",
    "plt.ylabel(\"Number of Employees\")\n",
    "plt.legend([\"Stayed\", \"Left\"])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 6: Feature Selection and Encoding\n",
    "# ------------------------------------------------------------\n",
    "le = LabelEncoder()\n",
    "data['salary'] = le.fit_transform(data['salary'])\n",
    "data['sales'] = le.fit_transform(data['sales'])\n",
    "\n",
    "selected_features = ['satisfaction_level', 'last_evaluation',\n",
    "                     'number_project', 'average_montly_hours',\n",
    "                     'time_spend_company', 'salary', 'sales']\n",
    "\n",
    "X = data[selected_features]\n",
    "y = data['left']\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 7: Train/Test Split & Scaling\n",
    "# ------------------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 8: Logistic Regression Model\n",
    "# ------------------------------------------------------------\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# STEP 9: Evaluation\n",
    "# ------------------------------------------------------------\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cr = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n✅ Model Accuracy: {acc*100:.2f}%\")\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", cr)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
